---
layout: post
title: "Day 18: Python Keras"
subtitle: "Imaging Processing"
date: 2020-08-12 21:00:00 +0800
background: '/img/posts/ml.jpg'
---

As part of my plan to dive deeper into image classification to compete more on Kaggle, I re-did the **Image Processing with Keras in Python** Course on [DataCamp](https://learn.datacamp.com/courses/image-processing-with-keras-in-python). The course covered the following topics:

* Convolutional Neural Networks (CNNs)
* Tweaking Convolutions
* Deep CNNs
* Improving CNNs
* Interpreting CNNs

I've copied my notes below. I will combine this set of notes with notes from other courses on neural networks before posting it in the resources section.

## Basic Neural Networks

### Fully-Connected NN
```py
from keras.layers import Dense
from keras.models import Sequential

# Initialise model
model = Sequential()

# Reshape data - n_samples x n_pixels in image
train_data = train_data.reshape((50, 784))

# Add layers
model.add(Dense(10, activation='relu', input_shape=(784,)))
model.add(Dense(10, activation='relu'))

# Output layer - softmax for class probabilities
model.add(Dense(3, activation='softmax'))

# Compile
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']    # What to report
)

# Fit
model.fit(
    train_data, train_labels,
    validation_split=0.2, epochs=3
)

# Evaluate
test_data = test_data.reshape((10, 784))
model.evaluate(test_data, test_labels)
```

## Convolutions

### Definition
Context:
* Natural images contain spatial correlations
* Pixels along an edge or contour have similar colours
* Looking for the same feature (e.g. orientation) in every location in an image is like a mathematical operation called a convolution

What a convolution is:
* Kernel:
    * A matrix that identifies a specific feature
    * Example: vertical line `[ [-1, 1], [-1, 1] ]`
* Slide kernel across an array
* Multiply the window of values in the array by the kernel
* This forms a new array called a **feature map**, because it contains a map of the location in the image that matches the features in the kernel

### Convolution Layers in Keras
* Connects to the previous layer through a convolution kernel
* Output of each unit in this layer is a convolution of a kernel over the image input
* Kernels are adjusted using back-propagation
* Has only one weight for each pixel in the **kernel** vs. one weight for each pixel in the *image* for dense layers
* Parameters:
    * `kernel_size=3` means the kernel of each unit has 9 pixels
    * 10 units means a total of 90 parameters
* Input shape is the size of each of the input images to the network

```py
from keras.layers import Conv2D, Dense, Flatten
from keras.model import Sequential

# Initialise model
model = Sequential()

# Add convolution layer
model.addConv2D(
    10, kernel_size=3, activation='relu',
    input_shape=(img_rows, img_cols, 1)
)

# Flatten feature map into a one-dimensional array
model.add(Flatten())

# Output layer
model.add(Dense(3, activation='softmax'))

# Compile
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Fit
model.fit(
    train_data, train_labels,
    validation_split=0.2,
    epochs=3, batch_size=10
)

# Evaluate
model.evaluate(test_data, test_labels, batch_size=10)
```

### Tweaking Convolutions
Size of output:

```
Output = ( (Input Size - Size of Kernel + 2 * Size of ZeroPadding) / Strides ) + 1
```

#### Zero Padding
* Add a pad of zeroes around the input image
* Increases the size of the feature map
* Consequence of not zero padding: will lose a pixel off the edge of the image in every subsequent layer
* Settings:
    * `valid`: No zero padding is added
    * `same`: Zero padding is applied so that the output of the convolution has the same size as the input to the convolution

```py
# Valid setting
model.add(Conv2D(
    10, kernel_size=3, activation='relu',
    input_shape=(img_rows, img_cols, 1)),
    padding='valid'
)

# Same setting
model.add(Conv2D(
    10, kernel_size=3, activation='relu',
    input_shape=(img_rows, img_cols, 1)),
    padding='same'
)
```

#### Stride
* Size of the step that we take with the kernel between input pixels
* Bigger stride = smaller output size

```py
# Stride size
model.add(Conv2D(
    10, kernel_size=3, activation='relu',
    input_shape=(img_rows, img_cols, 1)),
    strides=1
)
```

#### Dilation
* Sets a distance between subsequent pixels in a kernel

```py
# Stride size
model.add(Conv2D(
    10, kernel_size=3, activation='relu',
    input_shape=(img_rows, img_cols, 1)),
    dilation_rate=2
)
```

## Deep CNNs

### A Deep Network
* Multiply layers are added to mimic the human visual system, which has multiple layers of processing in it
* Things that kernels and feature maps in different layers respond to:
    * Early layers: Oriented lines and simple textures
    * Intermediate layers: Complex features like simple objects
    * Late Layers: Specific types of objects
* Layers allow NNs to gradually build up representations of objects in images from simple to more complex features to distinct categories of objects

```py
from keras.layers import Conv2D, Dense, Flatten
from keras.model import Sequential

# Initialise model
model = Sequential()

# Add convolution layer
model.addConv2D(
    10, kernel_size=3, activation='relu',
    input_shape=(img_rows, img_cols, 1)
)

# Add convolution layer
model.addConv2D(
    10, kernel_size=2, activation='relu'
)

# Flatten feature map into a one-dimensional array
model.add(Flatten())

# Output layer
model.add(Dense(3, activation='softmax'))

# Compile
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Fit
model.fit(
    train_data, train_labels,
    validation_split=0.2,
    epochs=3, batch_size=10
)

# Evaluate
model.evaluate(test_data, test_labels, batch_size=10)
```

### Considering the Number of Parameters
* Get description of model

```py
model.summary()
```

### Reducing the Number of Parameters

#### Pooling
* Summarise a group of pixels using a certain aggregation function e.g. max, min, mean
* Dramatically reduces the number of parameters
* Parameter in `MaxPool2D` is the size of the pooling window

```py
from keras.layers import Dense, Conv2D, Flatten, MaxPool2D

# Initialise model
model = Sequential()

# Add convolutional layer
model.add(Conv2D(5, kernel_size=3, activation='relu', input_shape=(img_rows, img_cols, 1)))

# Add pooling layer
model.add(MaxPool2D(2))

# Add another convolutional layer
model.add(Conv2D(15, kernel_size=3, activation='relu'))

# Add pooling layer
model.add(MaxPool2D(2))

# Flatten
model.add(Flatten())

# Output
model.add(Dense(3, activation='softmax'))
```

## Improving CNNs

### Learning Curves

```py
training = model.fit(train_data, train_labels,
                     epochs=3, validation_split=0.2)

import matplotlib.pyplot as plt

# Plot curves
plt.plot(training.history['loss'])
plt.plot(training.history['val_loss'])
plt.show()
```

### Saving the Best Parameters

```py
from keras.callbacks import ModelCheckpoint

# Set up checkpoint object
checkpoint = ModelCheckpoint('weights.hdf5', monitor='val_loss', save_best_only=True)

# Store in a list
callbacks_list = [checkpoint]

# Add to fit
model.fit(
    train_data, train_labels,
    validation_split=0.2, epochs=3,
    callbacks=callbacks_list
)

# Load weights
model.load_weights('weights.hdf5')

# Predict
model.predict_classes(test_data)
```

### Regularisation

#### Dropout
* In each learning step:
    * Select a subset of the units
    * Ignore it in the forward pass and in the back-propagation
* Trains many different networks on different parts of the data
* If part of the network becomes too sensitive to some noise in the data, other parts will compensate
* Add dropout only after the layer for which we want units to be ignored
* May not work well with BatchNorm

```py
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, Dropout

model = Sequential()
model.add(Conv2D(5, kernel_size=3, activation='relu', input_shape=(img_rows, img_cols, 1)))
model.add(Dropout(0.25))
model.add(Conv2D(15, kernel_size=3, activation='relu'))
model.add(Flatten())
model.add(Dense(3, activation='softmax'))
```

#### Batch Normalisation
* Rescale outputs from a layer
* Ensures mean 0 and SD 1
* Solves problem where different batches of input might produce wildly different distributions of outputs in the network
* Add BatchNorm after the layer whose output should be normalised
* May not work well with dropout

```py
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, BatchNorm

model = Sequential()
model.add(Conv2D(5, kernel_size=3, activation='relu', input_shape=(img_rows, img_cols, 1)))
model.add(BatchNormalization())
model.add(Conv2D(15, kernel_size=3, activation='relu'))
model.add(Flatten())
model.add(Dense(3, activation='softmax'))
```

## Interpreting NNs

### View Layers
See list of layers:

```py
model.layers
```

### Get weights
```py
# Get layer (convolutional)
conv1 = model.layers[0]

# Get weights of layer - list with
#   1. Weights of kernels for this layer
#   2. 
weights1 = conv1.get_weights()

# Get kernel properties - 4-dimensional array
#   1 and 2: Kernel size
#   3: No. of channels in the kernels
#   4: No. of kernels in this layer
kernels1 = weights1[0]
```