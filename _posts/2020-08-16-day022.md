---
layout: post
title: "Day 22: Python Keras"
subtitle: "Image Classification"
date: 2020-08-16 23:00:00 +0800
background: '/img/posts/ml.jpg'
---

I took a break from the course to consolidate my learning on Convolutional Neural Networks (CNNs). Today, I worked through another dataset to develop an image classification model, the **Multi-Type Aircraft of Remote Sensing Images (MTARSI)** dataset

MTARSI contained satellite images of several transport and fighter aircraft types. However, the dataset was rather problematic. Thanks to some EDA, I discovered that there were only a handful of unique images. The dataset actually comprised a lot of simulated data - the same aircraft images superimposed on different runway textures. In addition, many fighter aircraft (F-4, F-15, F-16, and F-18) were misclassified as F-22s. Attaching the right labels took some time.

The cleaned dataset comprised 1,717 training images and 428 test images with 12 classes:

1. B-1
2. B-2
3. B-52
4. Boeing (passenger aircraft)
5. C-130
6. C-17
7. C-5
8. e-3
9. F-16
10. F-18
11. KC-10
12. KC-135

I created a CNN with 4 x Convolutional + Max Pooling layers:

```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 145, 145, 32)      896       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 72, 72, 32)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 70, 70, 64)        18496     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 35, 35, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 33, 33, 64)        36928     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
flatten (Flatten)            (None, 3136)              0         
_________________________________________________________________
dense (Dense)                (None, 16)                50192     
_________________________________________________________________
dropout (Dropout)            (None, 16)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 12)                204       
=================================================================
Total params: 143,644
Trainable params: 143,644
Non-trainable params: 0
_________________________________________________________________
```

The results were weird. The validation accuracy was consistently higher than the training accuracy. Perhaps this was due to the synthetic images in the test set were too similar to those in the training set, or the train/test split (by ID) wasn't well done.

I learned that Keras' `ImageDataGenerator` class can take a `validation_split` parameter to randomly do a train/validation split for you. That could help improve the splits.

After working with this dataset, I think I want to do more practice on CNNs before moving over to RNNs, which is in the next chapter of the course.