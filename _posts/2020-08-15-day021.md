---
layout: post
title: "Day 21: Python Keras"
subtitle: "Convolutional Neural Networks"
date: 2020-08-15 23:00:00 +0800
background: '/img/posts/ml.jpg'
---

This is a continuation of the **Complete Tensorflow 2 and Keras Deep Learning Bootcamp** on [Udemy](https://www.udemy.com/course/complete-tensorflow-2-and-keras-deep-learning-bootcamp/). Today's session focused on Convolutional Neural Networks (CNNs).

Like the section on neural networks basics ([Day 19](https://chrischow.github.io/365DaysOfDS/2020/08/13/day019.html)), the theory of CNNs was not taught as well as Andrew Ng in his CNN course on [Coursera](https://www.coursera.org/learn/convolutional-neural-networks). Thankfully, the CNN course on [DataCamp](https://learn.datacamp.com/courses/image-processing-with-keras-in-python) was a good refresher. However, the code-along was great. The course went through the **Modified National Institute of Standards and Technology (MNIST) database for handwritten digits** and the **Canadian Institute For Advanced Research (CIFAR) 10 object recognition database**. These datasets are very popular and commonly-used for benchmarking. 

My notes were included below:

## Preparing Data

### One-hot Encoding the Target
The `to_categorical` function one-hot encodes the target.

```py
from tensorflow.keras.utils import to_categorical

# OHE target
y_train_labels = to_categorical(y_train)
```

### Scale Data
Divide train and test data by 255.

```py
X_train = X_train/255
X_test = X_test/255
```

### Configure Shape
To let the model know the number of channels:

```py
# Grayscale
X_train = X_train.reshape(n_samples, width, height, color_channels)
X_test = X_test.reshape(n_samples, width, height, color_channels)
```

### Dimension Size
* Images should all be of the same shape
* If images are not standardised, use the average of both dimensions
    * Pad images that are too small
    * Crop images that are too large

```py
dim1 = []
dim2 = []

for image_filename in os.listdir(folder):
    
    img = imread(folder + '\\' + image_filename)
    d1, d2, _ = img.shape
    dim1.append(d1)
    dim2.append(d2)
```

### Processing Images
* Use the `ImageDataGenerator` function
* Expands the number of images through transformations: rotate, resize, rescale
* Specifies many parameters
    * `rotation_range`: Random rotation within certain range of degrees
    * `width_shift_range`: Stretch width by certain percentage
    * `height_shift_range`: Stretch height by certain percentage
    * `rescale`: E.g. 1/255
    * `shear_range`: Cut away part of image by certain percentage
    * `zoom_range`: Randomly zoom in by certain percentage
    * `horizontal_flip` / `vertical_flip`: Randomly flip images
    * `fill_mode`: If transformation creates empty spots, how to fill - e.g. `nearest` pixel values
* Transformations depend on kind of image
    * E.g. blood cells can be stretched or rotated
    * E.g. faces should not be stretched or rotated

```py
# Initialise ImageDataGenerator
image_gen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    # rescale=1/255,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Demo of random transformation
plt.imshow(image_gen.random_transform(img_array)); plt.show()
```

### Loading Images
* Use the `.flow_from_directory` method of the `ImageDataGenerator`
* Directories in overarching directory must be organised in classes

```
Image Data Folder
    |
    |- Class 1
        |- Class 1 Images.png
    |- Class 2
        |- Class 2 Images.png
```

## Building the Model

### Common Parameters

* Number of filters: Power of 2
* Kernel size: (4,4)
* Pool size: Half of kernel size
* After Flatten layer: 1 or 2 Dense layers

### Model for Malaria Dataset

```py
model = Sequential()

model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(130,130, 3),
                activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Flatten())

model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(1, activation='sigmoid'))

model.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model.summary()
```

### Reading Data with Image Generators
* Specify respective data folder paths
* Set a target size
* Set color mode correctly based on channels available
* Set a batch size
* Set class mode (type of classification)
* Shuffle only for training data


```py
early_stop = EarlyStopping(monitor='val_loss', patience=2)

train_image_gen = image_gen.flow_from_directory(
    train_path,
    target_size=(130,130),
    color_mode='rgb',
    batch_size=16,
    class_mode='binary'
)

test_image_gen = image_gen.flow_from_directory(
    test_path,
    target_size=(130,130),
    color_mode='rgb',
    batch_size=16,
    class_mode='binary',
    shuffle=False
)
```

### Fit Model
Use the `.fit_generator` method:

```py
results = model.fit_generator(
    train_image_gen, epochs=20,
    validation_data=test_image_gen,
    callbacks=[early_stop]
)
```

### Evaluation
* Predict returns probabilities 

```py
# Evaluate
model.evaluate_generator(test_image_gen)

# Predict
pred = model.predict_generator(test_image_gen)
predictions = pred > 0.5

# Print results
print(classification_report(test_image_gen.classes, predictions))
print('AUC:', roc_auc_score(test_image_gen.classes, predictions))
```