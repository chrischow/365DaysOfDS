---
layout: post
title: "Day 7: Python"
subtitle: "Automated EDA: Detecting Data Measurement Types"
date: 2020-08-01 20:00:00 +0800
background: '/img/posts/ml.jpg'
---

## Automated EDA Tool
Yesterday, I wrote a function that drew heavily on Pandas' built-in functions to detect data types. Today, the focus is on writing a function to detect other characteristics of features in a dataset.

Remember, the idea for the automated EDA tool is to provide good insights and recommendations. It is not meant to dictate what characteristic each feature has and automatically process it without feedback from domain experts.

## Measurement Types
The conventional measurement scales include the following:

1. Nominal: Letters, words, and alphanumerics
2. Ordinal: Nominal with some order
3. Interval: Numbers with both order and standard distances between levels
4. Ratio: Interval that can include zero but no negative values

### Modification 1: Breaking Nominal Features Down
Building on this categorisation, I would break the nominal category down into categorical and text features because they are treated differently when it comes to the feature engineering stage. While categorical features will typically be encoded (e.g. mean encoding, one-hot encoding), text features are processed entirely differently. Feature extraction for text makes use of Natural Language Processing (NLP) techniques - and there are a ton of them. We need these tags (text/categorical) to automatically apply the right feature engineering techniques downstream.

### Modification 2: Drop Constants
Some datasets contain features that have only one unique value. The automated EDA tool should give these features a "drop" tag.

### Modification 3: Leave Booleans and Datetimes as They Are
Boolean and datetime features already follow a specific measurement ormat. There is no need to tag them further.

## Detecting Measurement Types

Following the style of yesterday's post, I will write code to identify each measurement type, and then combine them into a single function.

### Drop
This is the easiest to programme: just detect if the number of unique entries is less than or equal to 1. We will assign these features with the "drop" tag.

```py
# Detect features to drop
def featchar_drop(x):
    
    # Get valid entries
    total_valid, xvalid = get_valid(x)
    
    if xvalid.nunique() <= 1:
        return 'drop'
```

### Ratios and Intervals
Next, we'll move on to ratios and intervals, since these are relatively well-defined. Integers or floats that are non-negative are ratios, while those that can be negative are intervals. Note that there is some repetition from the numeric data type detector in the code below. We should refactor this by including it in the mega data detector function to stay aligned to the Don't Repeat Yourself (DRY) principle.

```py
# Detect ratios and intervals
def featchar_ratio_interval(x):
    
    # Get valid entries
    total_valid, xvalid = get_valid(x)
    
    try:
        # Try converting to numeric
        xconv = pd.to_numeric(xvalid)

    except ValueError:
        return ''
    
    if xvalid.str.contains('^0[0-9]').sum() > 0:
        return ''
    elif 'int' in str(xconv.dtypes) or 'float' in str(xconv.dtypes):
        if (xconv > 0).sum() == total_valid:
            return 'ratio'
        else:
            return 'interval'
    else:
        return ''
```

### Ordinal Features
Ordinal features are a lot trickier because (1) the ruleset is huge and (2) Pandas has no way to automate it this (so I can't be lazy). By ruleset, I'm referring to known ordinal categories like:

1. A, B, C, D, ...
2. XS, S, M, L, XL (and the fully-spelt words)
3. Strongly Disagree, Disagree, Slightly Disagree, Neutral, Slightly Agree, Agree, Strongly Agree
4. Poor, Acceptable, Fair, Good, Excellent
5. Fail, Pass, Merit, Distinction

We would need to build up a bank of these words, and check all sets if the feature contains several of the categories in each set. We set an arbitrary threshold of 20% for the proportion of values in a feature that exactly match any of the words in the list above. This is to provide sufficient flexibility for other categories that are not captured in this list. As we build up a more comprehensive list, we could increase this threshold.

Another more straightforward set of rules is to look at integer data types. If the data type is integer, we should check the number of unique values. A heuristic we could arbitrarily set is that if the number of unique values is less than or equal to 33% of the valid values in an integer feature, we will recommend the ordinal measurement type for that feature.

Let's begin with the above set of rules.

```py
# Detect ordinal features
def featchar_ordinal(x, ruleset_thresh=0.2, int_thresh=0.333):
    
    # Get valid entries
    total_valid, xvalid = get_valid(x)
    
    # Define standard ordinal categories
    cats = list('abcdefghijklmnopqrstuvwxyz') + \
        ['xs', 's', 'm', 'l', 'xl'] + \
        ['strongly disagree', 'disagree', 'slightly disagree', 'neutral',
         'slightly agree', 'agree', 'strongly agree'] + \
        ['poor', 'acceptable', 'fair', 'good', 'excellent'] + \
        ['fail', 'pass', 'merit', 'distinction']
    
    try:
        # Try converting to numeric
        xconv = pd.to_numeric(xvalid)

    except ValueError:
        if xvalid.isin(cats).sum() >= ruleset_thresh * total_valid:
            return 'ordinal'
        else:
            return ''
    
    if xvalid.str.contains('^0[0-9]').sum() > 0:
        return 'categorical'
    elif 'int' in str(xconv.dtypes):
        if xconv.nunique() <= int_thresh * total_valid:
            return 'ordinal'
        else:
            return ''
    else:
        return ''
```

### Nominal Features
Now, we address features that have not been assigned a characteristic yet. We differentiate between categorical and text features, noting the following characteristics:

| Characteristic | Categorical | Text |
| :------------- | :---------- | :--- |
| No. of unique entries | Fewer | More |
| Variation in length | Lower | Higher |
| Structure | Usually standardised | Unstructured |

Of the three, only the first two are easy to implement. We don't know what structure the values in these features could take. Therefore, we'll implement two rules:

1. An arbitrary threshold of 75% uniqueness to differentiate between text (>=75%) and categorical (<=75%) features.
2. A check for the length of the values in each feature. If there are 5 or fewer lengths, we assume that the values in the feature are relatively standardised, and are therefore categories.

```py
# Detect nominal features
def featchar_nominal(x, n_standards=5, unique_thresh=0.75):
    
    # Get valid entries
    total_valid, xvalid = get_valid(x)
    
    # Check for standardised lengths
    if xvalid.str.len().nunique() <= n_standards:
        return 'categorical'
    
    # Define standard ordinal categories
    elif xvalid.nunique() / total_valid >= unique_thresh:
        return 'text'
    else:
        return 'categorical'
```

## Re-factoring Functions
As we observed above, there was substantial overlap in the code. Several of the measurement types required checking for the numeric data format numerous times. Hence, I combined the functions I wrote yesterday with those written today to identify both data formats and measurement types:

```py
# Detect data types and measurement types
def detect_dtypes_measurement(x, ruleset_thresh=0.2, n_standards=5, unique_thresh=0.75, int_thresh=0.333):
    
    # Prepare output
    output = {
        'data_type': 'string',
        'measurement': []
    }
    
    # Get valid entries
    total_valid, xvalid = get_valid(x)
    
    # Check for boolean first
    if xvalid.nunique() == 2:
        output['data_type'] = 'bool'
        output['measurement'].append('bool')
        return output
    
    if xvalid.nunique() <= 1:
        output['data_type'] = 'unprocessed'
        output['measurement'].append('drop')
        return output
    
    # Check for numeric
    try:
        x_num = pd.to_numeric(xvalid)

    except ValueError:
        
        # Check for datetime
        try:
            # Try converting to datetime
            x_date = pd.to_datetime(xvalid)

        except ValueError:
            
            # Define standard ordinal categories
            cats = list('abcdefghijklmnopqrstuvwxyz') + \
                ['xs', 's', 'm', 'l', 'xl'] + \
                ['strongly disagree', 'disagree', 'slightly disagree', 'neutral',
                 'slightly agree', 'agree', 'strongly agree'] + \
                ['poor', 'acceptable', 'fair', 'good', 'excellent'] + \
                ['fail', 'pass', 'merit', 'distinction']
            
            # Check for ordinal
            if xvalid.isin(cats).sum() / total_valid >= ruleset_thresh:
                output['measurement'].append('ordinal')
            elif xvalid.str.len().nunique() <= n_standards:
                output['measurement'].append('categorical')
            elif xvalid.nunique() / total_valid >= unique_thresh:
                output['measurement'].append('text')
            else:
                output['measurement'].append('categorical')
            
            return output
        
        else:
            output['data_type'] = 'datetime'
            output['measurement'].append('datetime')
            return output
        
    else: 
    
        if 'int' in str(x_num.dtypes) or 'float' in str(x_num.dtypes):
            if (x_num > 0).sum() == total_valid:
                output['measurement'].append('ratio')
            else:
                output['measurement'].append('interval')

            if 'int' in str(x_num.dtypes):
                output['data_type'] = 'integer'
                if x_num.nunique() / total_valid <= int_thresh:
                    output['measurement'].append('ordinal')
            else:
                output['data_type'] = 'float'

            return output
        elif xvalid.str.contains('^0[0-9]').sum() > 0:
            output['measurement'].append('categorical')
            return output
    
    # Catchall: categorical string
    output['measurement'].append('categorical')
    return output
```