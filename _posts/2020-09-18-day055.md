---
layout: post
title: "Day 55: Python Keras"
subtitle: "Image Classification"
date: 2020-09-18 19:30:00 +0800
background: '/img/posts/ml.jpg'
---

Today's work was a continuation of my CNN model for the **Multi-Type Aircraft Remote Sensing Images (MTARSI)** dataset.

## Big Mistake
I found an error in my code. I accidentally set all layers in each pre-trained model to `True`, which means that I was effectively training all layers in each model, and the "unfreezing" was purely for regularisation (where I actually did apply regularisation). This is a **huge** setback to the progress for my post. I will have to re-train all the pre-trained models if I want to demonstrate "fine-tuning".

That said, some of my current results have some value. The models I tested were simply fully-trained models using known architectures, but with regularisation applied to only a subset of layers. This helped in some cases:

* Xception: Regularisation on all layers in blocks 8 to 14 was optimal
* VGG16: Regularisation on all layers was optimal
* ResNet50: Regularisation on only the final group of blocks (`Conv5`) was optimal

In fact, using models with these more complex architectures outperformed my custom-built model! The lessons learnt here are:

1. **CHECK YOUR CODE.**
2. If you don't know what architecture to use, start with proven architectures and work from there.

## True Fine-tuning
I re-ran each of the models with just 1 x FC layer (512 neurons) as the top, this time with the correct setting of `.trainable = False`.

#### Xception
Accuracy: 77%

#### VGG16
Accuracy: 85%

#### ResNet50
Accuracy: 68%

## InceptionResNet V2
The iteration below was for InceptionResNet V2 with **proper fine-tuning**.

#### Iteration 1
Parameters:
* Image size: 140x140
* Top: 1 x FC layer with 512 neurons
* Learning rate: 0.00001

Observations:
* Accuracy: 80%
